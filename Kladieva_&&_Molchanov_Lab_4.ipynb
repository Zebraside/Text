{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kladieva && Molchanov Lab 4.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DT15IvqS_VF4",
        "colab_type": "text"
      },
      "source": [
        "10 => (loss = :mrl, opt = :rmsprop, agg = :avg, constr = :nneg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMHvDjWS_VF5",
        "colab_type": "text"
      },
      "source": [
        "### 1. Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTWUk349_VF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def remove_blank_lines(filepath, pattern):\n",
        "    data = []\n",
        "    with open(filepath, \"r\", encoding=\"utf-8\") as file:\n",
        "        data.append(file.readline()) # append header\n",
        "        for line in file:\n",
        "            if line.startswith(pattern) and len(line.split(csv_separator)) == 4:\n",
        "                data.append(line)                \n",
        "    return data\n",
        "\n",
        "def preprocess_raw_files(folder_path, new_folder_path):\n",
        "    if not os.path.exists(new_folder_path):\n",
        "        os.makedirs(new_folder_path)\n",
        "    \n",
        "    for filename in os.listdir(folder_path):\n",
        "        data = remove_blank_lines(os.path.join(folder_path, filename), filename)\n",
        "        with open(os.path.join(new_folder_path, filename), \"w\", encoding=\"utf-8\") as file:\n",
        "            for line in data:\n",
        "                file.write(line)\n",
        "        \n",
        "data_folder = \"PrepData\"\n",
        "csv_separator = ';'\n",
        "preprocess_raw_files(\"Data\", data_folder)\n",
        "\n",
        "rows_to_read_from_each_topic = 2000 # use small values for debug\n",
        "test_size = 1000 # use small values for debug"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k79poPAo_VF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "def read_data(folder_path):\n",
        "    data = {}\n",
        "    for file in glob.glob(folder_path + \"/*\"):\n",
        "        csv_f = pd.read_csv(file, delimiter=\";\" ,nrows=rows_to_read_from_each_topic, index_col=2).T.to_dict()\n",
        "        for title in csv_f:\n",
        "            data[title] = csv_f[title][\"og:description\"]    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61kOoPuc_VGE",
        "colab_type": "text"
      },
      "source": [
        "### 2. Tokenize & create dictionary for unique most frequent words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0f5v_om_VGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = read_data(data_folder)\n",
        "\n",
        "import random\n",
        "print(random.sample(data.items(), 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mibkhy3_VGM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "squashed_data = [title + '\\n' + data[title] for title in data.keys()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSUdXdUz_VGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "words_dict = {}\n",
        "idx = 0\n",
        "vectorizer = CountVectorizer()\n",
        "\n",
        "def get_words_occurring_more_than(k):\n",
        "    bag_of_words = vectorizer.fit_transform(squashed_data)\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\n",
        "    return dict(filter(lambda x: x[1] > k, words_freq))\n",
        "\n",
        "words = get_words_occurring_more_than(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6wqbrJg_VGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words_dict = dict((v, k) for k, v in dict(enumerate(words.keys())).items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlniy90d_VGX",
        "colab_type": "text"
      },
      "source": [
        "### 4. Define function to represent text as a set of indexes in word_dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rt9rMP1V_VGY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def get_indices(text):\n",
        "    for (word, _) in re.findall(r'(\\w+(-\\w+)?)', text):\n",
        "        if word in words_dict:\n",
        "            yield words_dict[word]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OUgkKH8_VGd",
        "colab_type": "text"
      },
      "source": [
        "### 5. Initialize random vector for every word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMftQ_GQ_VGe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import normalize\n",
        "\n",
        "embedding_size = 32\n",
        "\n",
        "A = np.random.normal(0, 1, size=(embedding_size, len(words_dict)))\n",
        "A = normalize(A, axis = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nG35WPh_VGm",
        "colab_type": "text"
      },
      "source": [
        "### 6. Split data to train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Dbwd2T_VGn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(list(data.items()), test_size=test_size)\n",
        "title, desc = random.choice(train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MUfx826_VGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "title"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idG-Ieh0_VG0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "desc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEK4JC1F_VG4",
        "colab_type": "text"
      },
      "source": [
        "### 7. Define function for representing text in form of word indices in dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrDDWr4a_VG5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_vectors(text):\n",
        "    return A[:, list(get_indices(text))]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWy0RuGJ_VG8",
        "colab_type": "text"
      },
      "source": [
        "### 8. Define loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MA17MTiH_VG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss(u, v, v_hat, γ=1.0):\n",
        "    return γ - np.dot(u, v) + np.dot(u, v_hat)\n",
        "\n",
        "def calculate_gradients(u, v, v_hat):\n",
        "    l = loss(u, v, v_hat)\n",
        "    if l > 0:\n",
        "        return (np.subtract(v_hat, v), np.multiply(u, -1), np.array(u))\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu4g6DOf_VG_",
        "colab_type": "text"
      },
      "source": [
        "### 9. Define functions for quality testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT16GNe3_VHA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_aggregation(text):\n",
        "    vectors, indices = get_vectors(text), list(get_indices(text))\n",
        "    return np.mean(vectors, axis=(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFsvRORD_VHC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def top_k(vec, k):\n",
        "    return np.argpartition(vec, k)[:k, :]\n",
        "\n",
        "def recall(test):   \n",
        "    v_titles = [[v for v in get_aggregation(title)] for title, _ in test]\n",
        "    v_descs = [[v for v in get_aggregation(desc)] for _, desc in test]\n",
        "    dist = np.matmul(v_titles, np.transpose(v_descs))\n",
        "\n",
        "    ind = 0\n",
        "    tp = 0\n",
        "    for top in np.transpose(top_k(dist, 10)):\n",
        "        if ind in top:\n",
        "            tp += 1\n",
        "        ind += 1\n",
        "    return tp / len(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jym_ccH_VHG",
        "colab_type": "text"
      },
      "source": [
        "### 10. Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHVeov4o_VHJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_negative(A):\n",
        "    normalized = A + np.amin(A)\n",
        "    return normalized"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5xwbW_6_VHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def optimization_step(A, e_g, grads, eta, eps, decay=0.9):\n",
        "    for g in grads:\n",
        "        e_g = decay * e_g + (1 - decay) * g ** 2\n",
        "        delta = g * eta / np.sqrt(e_g + eps)\n",
        "        A -= np.transpose(delta)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9MrzruF_VHP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 100\n",
        "e_g = np.zeros((len(words_dict), embedding_size))\n",
        "eps = 1e-8\n",
        "eta = 1\n",
        "iters_per_epoch = 100000\n",
        "\n",
        "def train_sample(iter_num, A):\n",
        "    random.seed()\n",
        "    samples = random.sample(train, 2)\n",
        "    \n",
        "    title, desc = samples[0]\n",
        "    _, other_desc = samples[1]   \n",
        "    \n",
        "    title_vals = list(get_aggregation(title))\n",
        "    desc_vals = list(get_aggregation(desc))    \n",
        "    other_desc_vals =  list(get_aggregation(other_desc))\n",
        "    \n",
        "    grads = calculate_gradients(title_vals, desc_vals, other_desc_vals)\n",
        "    \n",
        "    if (grads):\n",
        "        optimization_step(A, e_g, grads, eta, eps)\n",
        "    \n",
        "    if iter_num % 1000 == 0:\n",
        "        A = remove_negative(A)\n",
        "\n",
        "recalls = []\n",
        "for epoch in range(epochs):\n",
        "    for i in range(iters_per_epoch):\n",
        "        #print(i)\n",
        "        train_sample(i, A)\n",
        "    r = recall(test)\n",
        "    recalls.append(r)\n",
        "    \n",
        "    print(\"Epoch {0} done. Recall: {1}\".format(epoch + 1, r))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1l5kI8Op_VHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}